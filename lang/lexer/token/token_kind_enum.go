// Code generated by go-enum DO NOT EDIT.
// Version:
// Revision:
// Build Date:
// Built By:

package token

import (
	"fmt"
	"strings"
)

const (
	// Describes a `/ * block comment * /`.
	BlockComment TokenKind = iota
	// Marks the end of any source snippet.
	End
	// Describes a `// line comment`.
	LineComment
	// Describes a token not expected by the lexer, e.g. "â„–".
	Unknown
	// Describes a `/` (typically used in division).
	Slash
	// Describes any kind of whitespace (e.g. \n, \t, etc.).
	Whitespace
)

var ErrInvalidTokenKind = fmt.Errorf("not a valid TokenKind, try [%s]", strings.Join(_TokenKindNames, ", "))

const _TokenKindName = "BlockCommentEndLineCommentUnknownSlashWhitespace"

var _TokenKindNames = []string{
	_TokenKindName[0:12],
	_TokenKindName[12:15],
	_TokenKindName[15:26],
	_TokenKindName[26:33],
	_TokenKindName[33:38],
	_TokenKindName[38:48],
}

// TokenKindNames returns a list of possible string values of TokenKind.
func TokenKindNames() []string {
	tmp := make([]string, len(_TokenKindNames))
	copy(tmp, _TokenKindNames)
	return tmp
}

var _TokenKindMap = map[TokenKind]string{
	BlockComment: _TokenKindName[0:12],
	End:          _TokenKindName[12:15],
	LineComment:  _TokenKindName[15:26],
	Unknown:      _TokenKindName[26:33],
	Slash:        _TokenKindName[33:38],
	Whitespace:   _TokenKindName[38:48],
}

// String implements the Stringer interface.
func (x TokenKind) String() string {
	if str, ok := _TokenKindMap[x]; ok {
		return str
	}
	return fmt.Sprintf("TokenKind(%d)", x)
}

var _TokenKindValue = map[string]TokenKind{
	_TokenKindName[0:12]:  BlockComment,
	_TokenKindName[12:15]: End,
	_TokenKindName[15:26]: LineComment,
	_TokenKindName[26:33]: Unknown,
	_TokenKindName[33:38]: Slash,
	_TokenKindName[38:48]: Whitespace,
}

// ParseTokenKind attempts to convert a string to a TokenKind.
func ParseTokenKind(name string) (TokenKind, error) {
	if x, ok := _TokenKindValue[name]; ok {
		return x, nil
	}
	return TokenKind(0), fmt.Errorf("%s is %w", name, ErrInvalidTokenKind)
}
